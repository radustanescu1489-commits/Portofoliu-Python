import ollama

# Script: 09_simple_chatbot.py
# Scop: Un chatbot interactiv care È›ine minte contextul conversaÈ›iei.

def porneste_chat():
    print("--- ğŸ¤– Chatbot Llama 3 (Local) ---")
    print("Scrie 'stop' sau 'exit' pentru a Ã®ncheia.\n")

    # Aici este SECRETUL: Lista de istoric
    # StocÄƒm toatÄƒ conversaÈ›ia ca AI-ul sÄƒ aibÄƒ context
    istoric = []

    while True:
        # 1. PreluÄƒm mesajul tÄƒu
        user_input = input("Tu: ")
        
        # VerificÄƒm dacÄƒ vrei sÄƒ ieÈ™i
        if user_input.lower() in ["stop", "exit", "pa"]:
            print("ğŸ¤– Chatbot: La revedere! O zi bunÄƒ.")
            break

        # 2. AdÄƒugÄƒm mesajul tÄƒu Ã®n istoric
        istoric.append({'role': 'user', 'content': user_input})

        print("AI: (GÃ¢ndeÈ™te...)")

        try:
            # 3. Trimitem TOT istoricul, nu doar ultima Ã®ntrebare
            raspuns = ollama.chat(model='llama3.2', messages=istoric)
            
            ai_message = raspuns['message']['content']
            
            # 4. AfiÈ™Äƒm rÄƒspunsul
            print(f"ğŸ¤– Llama: {ai_message}\n")
            
            # 5. AdÄƒugÄƒm È™i rÄƒspunsul AI-ului Ã®n istoric (ca sÄƒ È™tie ce a zis)
            istoric.append({'role': 'assistant', 'content': ai_message})

        except Exception as e:
            print(f"âŒ Eroare: {e}")

if __name__ == "__main__":
    porneste_chat()