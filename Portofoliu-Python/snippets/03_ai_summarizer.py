import requests
from bs4 import BeautifulSoup
import ollama

# Script: 03_ai_summarizer.py
# Scop: CiteÈ™te o paginÄƒ web È™i foloseÈ™te AI-ul local pentru a face un rezumat

def summarize_website(url):
    print(f"--- 1. Citesc site-ul: {url} ---")
    
    try:
        # Pasul 1: DescÄƒrcÄƒm conÈ›inutul
        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        
        if response.status_code != 200:
            print("âŒ Nu pot accesa site-ul.")
            return

        soup = BeautifulSoup(response.text, 'html.parser')
        
        # Pasul 2: CurÄƒÈ›Äƒm textul
        # LuÄƒm doar paragrafele <p>, ignorÄƒm meniurile È™i reclamele
        paragrafe = soup.find_all('p')
        text_curat = " ".join([p.text for p in paragrafe])
        
        # IMPORTANT: TÄƒiem textul dacÄƒ e prea lung (pentru vitezÄƒ)
        # LuÄƒm primele 3000 de caractere
        text_curat = text_curat[:3000]
        
        if len(text_curat) < 100:
            print("âŒ Site-ul are prea puÈ›in text pentru a fi rezumat.")
            return

        print("--- 2. Trimit textul la AI (GÃ¢ndeÈ™te...) ---")
        
        # Pasul 3: DiscutÄƒm cu Ollama
        prompt = f"""
        CiteÈ™te urmÄƒtorul text È™i fÄƒ un rezumat scurt, Ã®n limba romÃ¢nÄƒ, de maxim 3 idei principale (bullet points).
        
        TEXT:
        {text_curat}
        """
        
        rezultat = ollama.chat(model='llama3.2', messages=[
            {'role': 'user', 'content': prompt}
        ])
        
        # Pasul 4: AfiÈ™Äƒm rezultatul
        print("\nğŸ“ REZUMAT GENERAT DE AI:\n")
        print(rezultat['message']['content'])
        print("\n---------------------------------")

    except Exception as e:
        print(f"âŒ Eroare: {e}")

if __name__ == "__main__":
    # TestÄƒm pe o paginÄƒ Wikipedia (sau orice articol de È™tiri)
    link = "https://ro.wikipedia.org/wiki/Inteligen%C8%9B%C4%83_artificial%C4%83"
    summarize_website(link)